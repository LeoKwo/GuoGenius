from langchain.agents import AgentExecutor, OpenAIFunctionsAgent
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain.memory import ConversationTokenBufferMemory
from langchain.schema.messages import SystemMessage
import streamlit as st
from langchain_community.chat_models.tongyi import ChatTongyi
import os
from dotenv import load_dotenv
from tools import resumeTool
from PIL import Image
from pathlib import Path
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode

load_dotenv()

# define Tongyi LLM
model = ChatTongyi(
      model='qwen-turbo',
      api_key=os.getenv('DASHSCOPE_API_KEY'),
)

st.set_page_config(page_title="GuoGenius", page_icon="ğŸ’¡")
st.title("ğŸ’¡ GuoGenius")

# Define session state messages
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "assistant", 
            "content": "ä½ å¥½ğŸ‘‹ æˆ‘æ˜¯GuoGeniusã€‚æˆ‘æ˜¯éƒ­ç¿åº·çš„æ•°å­—åŒ–åˆ†èº«ï¼Œæ‹¥æœ‰å…³äºä»–çš„èŒä¸šç»å†å’ŒæŠ€èƒ½çš„ä¸€åˆ‡ä¿¡æ¯ã€‚æˆ‘å¯ä»¥å›ç­”æ‚¨çš„ä»»ä½•é—®é¢˜ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼"
        },
    ]

with st.expander("ğŸ’¡ äº†è§£æ›´å¤š", expanded=False):
    st.success("""
        ğŸ’¡ GuoGeniusæ˜¯éƒ­ç¿åº·çš„æ•°å­—åŒ–åˆ†èº«ï¼Œæ‹¥æœ‰å…³äºä»–çš„èŒä¸šç»å†å’ŒæŠ€èƒ½çš„ä¸€åˆ‡ä¿¡æ¯ã€‚
    """)
    st.info("""
        #### GuoGenius æŠ€æœ¯æ ˆ
        ```
        Streamlit
        LangChain
        LlamaIndex
        é€šä¹‰åƒé—®Turbo (qwen-turbo)
        é˜¿é‡Œäº‘é€šç”¨æ–‡æœ¬å‘é‡æ¨¡å‹-v3 (text-embedding-v3)
        é˜¿é‡Œäº‘è½»é‡åŒ–æœåŠ¡å™¨
        ```
        æ­¤é¡¹ç›®å·²å¼€æºï¼š[https://github.com/LeoKwo/GuoGenius](https://github.com/LeoKwo/GuoGenius)
    """)

# Define Tools for the bot
tools = [resumeTool]
tool_node = ToolNode(tools)

# define memory
memory = MemorySaver()

# define LLM agent executor
agent_executor = create_react_agent(
    model=model, tools=tools, checkpointer=memory
)

# Define starter identity prompt
prompt = OpenAIFunctionsAgent.create_prompt(
    SystemMessage(content=("""
            éƒ­ç¿åº·ï¼ˆLeo Guoï¼‰åˆ›é€ çš„ GuoGeniusã€‚
            ä½ æ˜¯éƒ­ç¿åº·çš„æ•°å­—åŒ–äººæ ¼ï¼Œè´Ÿè´£å›ç­”å…³äºéƒ­ç¿åº·çš„ä¸“ä¸šç»éªŒã€æ•™è‚²èƒŒæ™¯ä»¥åŠå…¶ä»–ä¸èŒä¸šç›¸å…³çš„è¯é¢˜çš„é—®é¢˜ã€‚
            ä½ å¯ä»¥æŸ¥è¯¢éƒ­ç¿åº·çŸ¥è¯†åº“ä»¥è·å–ä¿¡æ¯ï¼Œä½†é™¤æ­¤ä¹‹å¤–å¯¹éƒ­ç¿åº·ä¸€æ— æ‰€çŸ¥ã€‚
            åœ¨å›ç­”é—®é¢˜æ—¶ï¼Œä½ åº”è¯¥å§‹ç»ˆé¦–å…ˆæŸ¥è¯¢çŸ¥è¯†åº“ä¸­ä¸é—®é¢˜æ¦‚å¿µç›¸å…³çš„ä¿¡æ¯ã€‚

            ä¾‹å¦‚ï¼Œç»™å®šä»¥ä¸‹è¾“å…¥é—®é¢˜ï¼š
            â€”â€“ç¤ºä¾‹è¾“å…¥é—®é¢˜å¼€å§‹â€”â€“
            éƒ­ç¿åº·åœ¨ Day & Nite çš„ç°ä»»å·¥ä½œä¸­è¡¨ç°å¦‚ä½•ï¼Ÿ
            â€”â€“ç¤ºä¾‹è¾“å…¥é—®é¢˜ç»“æŸâ€”â€“
            ä½ çš„ç ”ç©¶æµç¨‹åº”ä¸ºï¼š
                1.	æŸ¥è¯¢ä½ çš„çŸ¥è¯†åº“å·¥å…·ï¼ˆresumeToolï¼‰ï¼Œè·å–å…³äºâ€œå·¥ä½œâ€çš„ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
                2.	æ ¹æ®ä½ æ”¶é›†çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚
            å¦‚æœæ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œç»ä¸è¦ç¼–é€ ç­”æ¡ˆã€‚ç›´æ¥è¯´æ˜ä½ ä¸çŸ¥é“å³å¯ã€‚
            
            å°½å¯èƒ½å®Œæ•´åœ°å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
        """)
    ),
)

for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        st.chat_message("assistant", avatar=Image.open(Path("./pics/bot.jpg"))).write(msg["content"])

    else:
        st.chat_message("user", avatar="ğŸ˜").write(msg["content"])

if prompt := st.chat_input(placeholder="æ‚¨çš„é—®é¢˜..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user", avatar="ğŸ˜").write(prompt)
    with st.chat_message("assistant", avatar=Image.open(Path("./pics/bot.jpg"))):
        st.write("ğŸ§  Thinking...")
        st_callback_handler = StreamlitCallbackHandler(st.container())
        try:
            # print(prompt)
            response = agent_executor.invoke({
                        "messages": [
                            ("user", prompt)
                        ]
                    },
                    {"configurable": {"thread_id": 0}}
                )["messages"][-1].content
            # response = agent_chain.run(prompt, callbacks=[st_callback_handler])

        except ValueError as e:
            response = str(e)
            if not response.startswith("Could not parse LLM output: `"):
                # raise error
                response = f"{response.replace('Could not parse LLM output:', '')}"
                response.replace("Could not parse LLM output:", "")
            else:
                response = response.removeprefix("Could not parse LLM output: `").removesuffix("`")

        st.session_state.messages.append({"role": "assistant", "content": response})
        st.write(response)
        